{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Lab 1: Naive Models\n",
    "\n",
    "In any forecasting study the first thing you need to do is create a naive benchmark.  We can use naive benchmarks as simple methods for producing forecasting or as a way to check that the more complicated models we will use later the course are worth the effort to use/maintain.\n",
    "\n",
    "ðŸŽ“ **In this practical will apply our knowledge in**\n",
    "\n",
    "* âœ… Creating baseline naive forecasts\n",
    "* âœ… Performing a train-test split\n",
    "* âœ… Using forecast error metrics MAE and MAPE to select the best method \n",
    "* âœ… Producing prediction intervals for naive methods\n",
    "* âœ… Analysing prediction intervals using formal metrics as part of model comparison.\n",
    "* ðŸŽ **Bonus**: visualising time series with `forecast-tools` \n",
    "\n",
    "---\n",
    "**Before attempting the exercises, it is recommended that you watch the following code along tutorials that describes how to use python for basic forecasting**.\n",
    "\n",
    "* **Reading time series data into pandas**:\n",
    "    * Code along video (5 mins): https://bit.ly/pandas_ts\n",
    "    * [Code along notebook](https://colab.research.google.com/github/health-data-science-OR/forecasting/blob/master/01_basics/01_code_along_notebooks/pandas_time_series.ipynb)\n",
    "    \n",
    "* **Benchmark models**:\n",
    "    * Code along video (15 mins): https://bit.ly/benchmark_code_along\n",
    "    * [Code along notebook](https://colab.research.google.com/github/health-data-science-OR/forecasting/blob/master/01_basics/01_code_along_notebooks/ca_benchmark_forecasts.ipynb)\n",
    "    \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from numpy.typing import ArrayLike\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Install forecast-tools`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if running in Google Colab install forecast-tools\n",
    "if 'google.colab' in sys.modules:\n",
    "    !pip install forecast-tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `forecast-tools` imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#baseline forecast methods\n",
    "from forecast_tools.baseline import (\n",
    "    Naive1, \n",
    "    SNaive,\n",
    "    Drift,\n",
    "    Average,\n",
    "    baseline_estimators\n",
    ")\n",
    "\n",
    "from forecast_tools.metrics import(\n",
    "    mean_absolute_percentage_error,\n",
    "    mean_absolute_error,\n",
    "    winkler_score,\n",
    "    absolute_coverage_difference,\n",
    "    coverage,\n",
    ")\n",
    "\n",
    "from forecast_tools.plotting import plot_time_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions\n",
    "\n",
    "The naive forecasting methods generate forecasts and prediction intervals in a `np.ndarray`.  For convenience I have included two two helper functions to convert these arrary to a `pd.DataFrame` with a `DateTimeIndex`. This is helpful for plotting where the date is needed.\n",
    "\n",
    "> ðŸŽ“ You are free to use these functions in your own work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preds_as_series(data: ArrayLike, preds: np.ndarray) -> pd.DataFrame:\n",
    "    '''\n",
    "    Helper function for plotting predictions.\n",
    "    \n",
    "    Converts a 1D numpy array of predictions to a \n",
    "    pandas.DataFrame with datetimeindex\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "    data: arraylike\n",
    "        The training data\n",
    "    preds: np.array\n",
    "        Vector of predictions \n",
    "    \n",
    "    Returns:\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "    '''\n",
    "    start = pd.date_range(\n",
    "        start=data.index.max(), \n",
    "        periods=2, \n",
    "        freq=data.index.freq\n",
    "    ).max()\n",
    "    \n",
    "    idx = pd.date_range(start=start, periods=len(preds), freq=data.index.freq)\n",
    "    return pd.DataFrame(preds, index=idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intervals_as_dataframe(\n",
    "    intervals: np.ndarray, \n",
    "    test: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    '''\n",
    "    Helper function for plotting predictions.\n",
    "    \n",
    "    Converts 2D numpy array containing prediction intervals to a \n",
    "    pandas.DataFrame with datetimeindex.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    intervals: np.ndarray \n",
    "        matrix of prediction intervals\n",
    "\n",
    "    test: pd.DataFrame\n",
    "        test in a dataframe format. This is passed to extract the datetimeindex\n",
    "        to use in the new intervals dataframe.\n",
    "    '''\n",
    "    formatted_intervals = pd.DataFrame(\n",
    "        intervals, \n",
    "        index=test.index, \n",
    "        columns=[\"lower\", \"upper\"]\n",
    "    )\n",
    "\n",
    "    return formatted_intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Using Naive1 to forecast monthly outpatient appointments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1: Import monthly outpatient appointments time series**  \n",
    "\n",
    "This can be found in **\"data/out_appoints_mth.csv\"**\n",
    "or 'https://raw.githubusercontent.com/health-data-science-OR/hpdm097-datasets/master/out_appoints_mth.csv'\n",
    "\n",
    "* Hint: this is monthly data.  You can use the monthly Start ('MS') frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here ...\n",
    "url = 'https://raw.githubusercontent.com/health-data-science-OR/' \\\n",
    "        + 'hpdm097-datasets/master/out_appoints_mth.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2 Plot the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3: Create and fit Naive1 forecast model**\n",
    "\n",
    "* Hint: you want to fit `appoints['out_apts']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4: Plot the Naive1 fitted values**\n",
    "\n",
    "All the baseline models have fitted values.  These are the in-sample prediction i.e. the predictions of the training data.\n",
    "\n",
    "Once you have created and fitted a Naive1 model you can access the fitted values using the `.fittedvalues` property.  This returns a `DataFrame`.\n",
    "\n",
    "Plot the fitted values against the observed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5: Forecast the next 6 months**\n",
    "\n",
    "After you have created a forecast plot the predictions.  \n",
    "\n",
    "* Hint: use the `pred_as_series()` method to plot the predictions.  See the lecture notes for exampes of how to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2. Choose the best baseline forecast method for ED reattendances using point forecasts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1: Import emergency department reattendance data.**  \n",
    "\n",
    "This is a time series from a hospital that measures the number of patients per month that have reattended an ED within 7 days of a previous attendance.\n",
    "\n",
    "This can be found in **\"ed_reattend.csv\"**:  \n",
    "'https://raw.githubusercontent.com/health-data-science-OR/hpdm097-datasets/master/ed_reattend.csv'\n",
    "\n",
    "* Hint 1: The format of the 'date' column is in UK standard dd/mm/yyyy.  You will need to set the `dayfirst=True` of `pd.read_csv()` to make sure pandas interprets the dates correctly.\n",
    "\n",
    "* Hint 2: The data is monthly and the dates are all the first day of the month.  This is called monthly start and its shorthand is 'MS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here ...\n",
    "url = 'https://raw.githubusercontent.com/health-data-science-OR/' \\\n",
    "       + 'hpdm097-datasets/master/ed_reattend.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2: Perform a calender adjustment**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3: Perform a train-test split**\n",
    "\n",
    "Create a train test split where you holdback the final 6 months of the data.\n",
    "\n",
    "Remember to work with the calender adjusted data.\n",
    "\n",
    "* Hint: The test set is the last 6 rows in your pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4: Plot the TRAINING data**\n",
    "\n",
    "Remember don't look at the test data just yet.  You don't want to bias your model selection process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5: Create and fit Naive1, and SNaive baseline models**\n",
    "\n",
    "* Hint: Fit the TRAINING data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 6: Use each model to predict 6 months ahead**\n",
    "\n",
    "* Hint.  You need to store the prediction results so that later on you can calculate the forecast error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 7: Calculate the mean absolute error of each forecast method**\n",
    "    \n",
    "Based on the results which method would you choose?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Evaluate prediction intervals\n",
    "\n",
    "The evaluation of a forecasting model can be enhanced by analysing prediction intervals.  You can do this visually or if you are conducting a more rigourous analysis using formal interval scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1: Produce 80 and 95% prediction intervals for the model 1.**\n",
    "\n",
    "To obtain the prediction intervals we need to set the `return_predict_int` parameters of the `predict` function to `True`. E.g. \n",
    "\n",
    "```python\n",
    "preds_naive, intervals_naive = model_1.predict(\n",
    "    horizon=6, \n",
    "    return_predict_int=True, \n",
    "    alpha=[0.2, 0.05]\n",
    ")\n",
    "```\n",
    "\n",
    "The `alpha` parameter accepts a list that contains the 100(1-`alpha`) prediction interval requests. For example, [0.2, 0.05] returns arrary containing both 80% and 95% prediction intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To help visualise the return values you can convert the arrays to `DataFrame` using the `intervals_as_dataframe` helper function from the top of the notebook.  \n",
    "\n",
    "* This will print out the intervals in nicely formatted text.\n",
    "* Remember that in healthcare we are often predicting numbers of people. So consider how many decimal places are useful.\n",
    "\n",
    "> ðŸ’¡ I've used a dictionary comprehension below to create the keys and `DataFrames` for the naive1 prediction intervals in one go.  Remember this is just a loop and the code is just converting `np.array` objects into `pd.DataFrame` objects to help us inspect the intervals. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2: Produce 80 and 95% prediction intervals for the model 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3: Visualise the prediction intervals for both models**\n",
    "\n",
    "This is only practical when you have a small number of time series and models. \n",
    "\n",
    "You can create your own `matplotlib` functions for plotting. Alternatively for simple interactive plotting you could make use of the `forecast_tools.plotting.plot_time_series` function. It requires you to manipulate your data slightly:\n",
    "\n",
    "```python\n",
    "_ = plot_time_series(\n",
    "    training_data = pd.DataFrame(train),\n",
    "    test_data = pd.DataFrame(test),\n",
    "    forecast = pd.DataFrame(preds_naive1, index=test.index),\n",
    "    prediction_intervals = intervals_naive1_dict,\n",
    "    y_axis_label=\"Reattendances\",\n",
    ")\n",
    "```\n",
    "\n",
    "**Important usage notes**:\n",
    "\n",
    "* The function requires you to pass in the training, test, and forecast data in as a `pd.DataFrame`. Note I have converted the types here.\n",
    "\n",
    "* We need to make that our forecasting `pd.DataFrame` has the same `DateTimeIndex` as test. i.e.\n",
    "\n",
    "```python\n",
    "forecast = pd.DataFrame(preds_naive1, index=test.index),\n",
    "```\n",
    "\n",
    "* The `prediction_intervals` parameter expects a dictionary object containing `pd.DataFrame` objects. We have already created this early to inspect prediction intervals.\n",
    "\n",
    "ðŸ’¡ Does the shape of the prediction intervals alter your decision?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4: Calculate prediction interval scores for 80% intervals**\n",
    "\n",
    "* Here we will calculate the Winkler score, absolute coverage difference, and empirical coverage\n",
    "* Do the results alter your decision?\n",
    "* Which measure(s) were the most useful for this time series?\n",
    "\n",
    "\n",
    "ðŸ’¡ **In a formal lab report consider producing a formatted table all metrics (point forecasts and prediction intervals) using pandas.**\n",
    "\n",
    "> Also see: `forecast-tools` [documentation](https://tommonks.github.io/forecast-tools/content/02a_coverage_metrics.html)\n",
    "\n",
    "**Empirical Coverage**\n",
    "\n",
    "A simple way provide a score to a prediction interval is to quantify its empirical coverage of a test set. I.e. the percentage of points that fall within the interval.  For a 80% interval you aims for 80% of the points to fall within it.\n",
    "\n",
    "You can use the `coverage` function from `forecast_tools.metrics` (imported at top of notebook) to calculate it. E.g.\n",
    "\n",
    "```python\n",
    "cover_naive1 = coverage(y_true=test, pred_intervals=intervals_naive1[0])\n",
    "```\n",
    "\n",
    "Make sure you replace `test` and `intervals_naive1[0]` with the names of your variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Absolute Coverage Difference (ACD)**\n",
    "\n",
    "The absolute coverage difference is the absolute difference between empirical coverage and the target coverage level.\n",
    "\n",
    "For example if the average coverage is 83% and the target is a 95% coverage then the absolute coverage difference is\n",
    "\n",
    "$|0.83 - 0.95| = 0.12$\n",
    "\n",
    "**Smaller ACD scores are better.**\n",
    "\n",
    "Use the `forecast_tools.metrics.absolute_coverage_difference` function to calculate the ACD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Winkler score**\n",
    "\n",
    "A Winkler score is the width of the prediction interval plus a penalty proportional to the deviation (above or below the interval) and 2/$\\alpha$\n",
    "\n",
    "The Winkler score is defined as\n",
    "\n",
    "$$W_{\\alpha,t} = \\begin{cases}\n",
    "  (u_{\\alpha,t} - \\ell_{\\alpha,t}) + \\frac{2}{\\alpha} (\\ell_{\\alpha,t} - y_t) & \\text{if } y_t < \\ell_{\\alpha,t} \\\\\n",
    "  (u_{\\alpha,t} - \\ell_{\\alpha,t})   & \\text{if }  \\ell_{\\alpha,t} \\le y_t \\le u_{\\alpha,t} \\\\\n",
    "  (u_{\\alpha,t} - \\ell_{\\alpha,t}) + \\frac{2}{\\alpha} (y_t - u_{\\alpha,t}) & \\text{if } y_t > u_{\\alpha,t}.\n",
    "  \\end{cases}$$\n",
    "  \n",
    "  \n",
    "Where \n",
    "\n",
    "* $u_{\\alpha, t}$ is the upper prediction interval value for $\\alpha$ and horizon $t$\n",
    "* $l_{\\alpha, t}$ is the lower prediction interval value for $\\alpha$ and horizon $t$\n",
    "* $y_t$ is the ground truth observation at horizon $t$\n",
    "\n",
    "**smaller winkler scores are better!**\n",
    "\n",
    "You can use `forecast_tools.metrics.winkler_score` to calculate it. For example:\n",
    "\n",
    "```python\n",
    "# test = test data\n",
    "# intervals_naive1[0] = array of 80% prediction intervals\n",
    "# alpha = 0.2 for a 80% prediction interval and 0.05 for a 95% prediction interval.\n",
    "winkler_naive1 = winkler_score(\n",
    "    y_true=test, \n",
    "    intervals=intervals_naive1[0], \n",
    "    alpha=0.2\n",
    ")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
