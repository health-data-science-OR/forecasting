{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Lab 3: Introduction to **A**uto**R**egressive **I**ntegrated **M**oving **A**verage (ARIMA) Modelling\n",
    "\n",
    "**In this practical you will learn:**\n",
    "\n",
    "* How to automatically select ARIMA model parameters by minimising AIC\n",
    "* How to fit an ARIMA model to a time series\n",
    "* How to obtain a point forecast and prediction intervals using ARIMA\n",
    "* How to use `pmdarima`'s built in cross validation tools\n",
    "\n",
    "---\n",
    "* Introduction to Notebook: https://bit.ly/arima_intro\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARIMA specific imports\n",
    "\n",
    "There are two main libraries for ARIMA modelling in Python: `statsmodels` and `pmdarima`.  The latter builds a powerful package of tools on top of `statsmodels` to support ARIMA modelling.  We are going to primarily work with `pmdarima`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment and run if you are working in Google Colab\n",
    "#!pip install pmdarima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pmdarima import auto_arima, ARIMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports from `forecast-tools`\n",
    "\n",
    "One of the exercises with compare ARIMA to a simple baseline forecast if are working from Google Colab (or not using `hds_stoch` environment) them please uncomment and run the below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install forecast-tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from forecast_tools.baseline import SNaive\n",
    "from forecast_tools.metrics import mean_absolute_error\n",
    "from forecast_tools.model_selection import (rolling_forecast_origin, \n",
    "                                            cross_validation_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arima_preds_to_dataframe(y_train, preds, intervals):\n",
    "    '''\n",
    "    pdmarima.ARIMA models return point forecasts and prediction intervals\n",
    "    as numpy arrays.  This function converts them into data frames with a\n",
    "    DateTimeIndex.\n",
    "    \n",
    "    Parameters:\n",
    "    ---------\n",
    "    y_train: pd.DataFrame or pd.Series\n",
    "        Training data\n",
    "        \n",
    "    preds: np.array\n",
    "        point forecasts\n",
    "        \n",
    "    intervals: np.array\n",
    "        matrix - prediction intervals\n",
    "        \n",
    "    Returns:\n",
    "    -------\n",
    "        pd.DataFrame['mean'], pd.DataFrame['lower'. 'upper']\n",
    "        \n",
    "    '''\n",
    "    pred_idx = pd.date_range(start=y_train.index[-1], periods=len(preds)+1, \n",
    "                             freq=y_train.index.freq)[1:]\n",
    "    \n",
    "    preds = pd.DataFrame(preds, index=pred_idx)\n",
    "    preds.columns = ['mean']\n",
    "    intervals = pd.DataFrame(intervals, index=pred_idx)\n",
    "    intervals.columns = ['lower', 'upper']\n",
    "    \n",
    "    return preds, intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "We will use an time series of patients that reattend an ED within 7 days.  The data are held at the monthly level.\n",
    "\n",
    "The data is held in the file `ed_reattends_mth.csv`\n",
    "\n",
    "# Exercise 1: Read in and adjust\n",
    "\n",
    "**Task:**\n",
    "\n",
    "* Load `ed_reattends_mth.csv`\n",
    "* Perform a calender adjustment of the data\n",
    "* Plot the data\n",
    "* Name the `pd.DataFrame` you create `y_train`\n",
    "\n",
    "**Hints**\n",
    "\n",
    "* The data is stored in UK day first format.\n",
    "* Remember to set the freq of the DataTimeIndex\n",
    "\n",
    "\n",
    "**Questions**:\n",
    "* How would you describe the time series?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here ...\n",
    "url = 'https://raw.githubusercontent.com/health-data-science-OR/hpdm097-datasets/master/ed_reattends_mth.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we use ARIMA it is necessary to understand the a two concepts: **autocorrelation** and **stationarity**\n",
    "\n",
    "# Autocorrelation \n",
    "\n",
    "Autocorrelation (sometimes called serial correlation) describes the correlation of air passengers at time $t$ with air passengers at $t-1, t-2, ... , t-n$. In other words autocorrelation is the correlation of an observation with itself at previous time periods.  Like correlation autocorrelation takes a value between -1.0 ans 1.0\n",
    "\n",
    "Let's have a look at the autocorrelation in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acf(y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autocorrelation is a problem for traditional Ordinary Least Squares (OLS) regression because OLS assumes that the error process is normal i.i.d (independent and identitically distributed = there is no pattern).  In the ED 7-day Reattendance dataset this clearly isn't the case: there is significant autocorrelation up to lag 3 and possibly up to lag 6.\n",
    "\n",
    "In the presence of autocorrelation, the standard errors of the coefficients from an OLS regression are too small and cannot be trusted. This is a substative problem for *inference* (i.e drawing the wrong conclusion, but and it is also a significant disadvantage for forecasting as we are ignoring information that could improve point predictions and prediction intervals.  \n",
    "\n",
    "ARIMA models aim to describe the autocorrelations in the data. \n",
    "\n",
    "**AR** - Stands for Autoregressive. An AR(1) model is a regression model that includes a proportion of lag 1 Y value.  An AR(2) model includes a proportion of lag 1 and lag 2.  An AR(p) model includes a proportion of lags 1 to $p$.  An AR model of order p can be written as:\n",
    "\n",
    "$y_t = c + \\phi_1 y_{t-1} + \\phi_2 y_{t-2} ⋯ \\phi_p y_{t-p} + \\epsilon_t$\n",
    "* where $\\epsilon_t$ is white noise (random error)\n",
    "* The equation above looks like a regression with lagged variables of y\n",
    "\n",
    "\n",
    "**MA** - Stands for Moving Average. An MA(1) model is a regression model that includes a proportion of the lag 1 forecast error value.  An MA(q) model includes a proportion of the errors from lag 1 to q.  An MA model of order q can be written as:\n",
    "\n",
    "$y_t = c + \\epsilon_t + \\theta_1 \\epsilon_{t-1} + \\theta_2 \\epsilon_{t-2} ⋯ \\theta_q \\epsilon_{t-q}$\n",
    "\n",
    "\n",
    "ARIMA models can include a both AR and MA terms at the same time.\n",
    "\n",
    "$y_t = c + \\phi_1 y_{t-1} + \\phi_2 y_{t-2} ⋯ \\phi_p y_{t-p} + \\epsilon_t + \\theta_1 \\epsilon_{t-1} + \\theta_2 \\epsilon_{t-2} ⋯ \\theta_q \\epsilon_{t-q}$\n",
    "\n",
    "#### Seasonal lags\n",
    "ARIMA models can also include seasonal AR and MA terms (along with a seasonal period e.g 12 for monthly data). For example, an AR(P) model where P = 1 would include lag 12.  If P = 2 then it would include lag 12 and lag 24."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic selection of the 'best' ARIMA model.\n",
    "\n",
    "The `pmdarima` package is an excellent forecasting library for building ARIMA models.  I recommend it over and above the options available in core `statsmodels` package.  It is easier to use and offers an `auto_arima()` function that iteratively searches for a model that minimises the **Akaike Information Criterion (AIC)**\n",
    "\n",
    "* ${\\displaystyle \\mathrm {AIC} \\,=\\,2k-2\\ln({\\hat {L}})}$\n",
    "\n",
    "where $k$ = number of parameters in the model and $\\hat{L}$ is the maximum value of the likelihood function for the model.  A likelihood function measures the 'goodness' of fit of a model to data given a set of parameters.  \n",
    "\n",
    "This looks very complicated at first, but all we need to remember that the models we are working with are very flexible. This means that we can easily create complex models that overfit.  Recall that overfitting is when a model will predict the training data exceptionally well, but will perform poorly on out of sample data.  The form of AIC means that it rewards models that fit the training data well, but also penalises models with high $k$ (complicated models with lots of parameters).  That means that AIC will prefer simpler models - in turn reducing overfitting.  That's a great formaula for automatically selecting a good ARIMA forecasting model.\n",
    "\n",
    "There's a large amount of theory about how to build an ARIMA model.  But modern applications tend to opt for the auto approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2: Using `auto_arima`\n",
    "\n",
    "Let's use `auto_arima` keeping most parameters as their defaults initially.\n",
    "\n",
    "**Task**: \n",
    "\n",
    "* Use `auto_arima` to find a model.  \n",
    "* One a model is returned (it will take a few seconds) call `model.summary()` this will print out the models parameters.\n",
    "\n",
    "**Hints**:\n",
    "* This is monthly data.  We will need to set the parameter `m=12` so that the function knows the seasonal period.\n",
    "* Not all models that the function attempts to fit will converge.  In these instances `statsmodels` will raise *warnings*.  To suppress these set `suppress_warnings=True`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3: Forcing a first difference\n",
    "\n",
    "The previous auto fitting returned a ARIMA(1, 0, 0)x(1, 0, 0, 12) model.  In this model `d=0` which means that the first stage of the auto fitting chose not to take a first difference.  Let's force `auto_arima` to fit models using a first difference of the data.\n",
    "\n",
    "**Task:**\n",
    "* rerun `auto_fit`, but set `d=1`\n",
    "\n",
    "\n",
    "**Questions**\n",
    "* Did the function return a different model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4: Manually creating a `ARIMA` model\n",
    "\n",
    "In `pmdarima` you create an `ARIMA` object by passing in the (p, d, q) order and the (P, D, Q, m) seasonal order.\n",
    "    \n",
    "```python\n",
    "\n",
    "#create an ARIMA object (suppress_warnings is optional)\n",
    "model = ARIMA(order=(1, 0, 0), seasonal_order=(1, 0, 0, 12), \n",
    "              suppress_warnings=True)\n",
    "\n",
    "#fit the model to the training data.\n",
    "model.fit(y_train)\n",
    "\n",
    "```\n",
    "\n",
    "**Task:**\n",
    "\n",
    "* Manually create and fit ARIMA model with `order=(3, 1, 0)` and `seasonal_order=(1, 0, 0, 12)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 5: Making a prediction\n",
    "\n",
    "To make a prediction with a `pmdarima.ARIMA` model use the `model.predict()` method.  This takes the parameters `n_periods` which is the forecast horizon.\n",
    "\n",
    "```python\n",
    "#return a numpy.array of predictions\n",
    "preds = model.predict(n_periods=12)\n",
    "```\n",
    "\n",
    "You can (and should) also return a prediction interval with the point forecast. E.g. for a 95\\% PI:\n",
    "\n",
    "```python\n",
    "#returns a tuple of (predictions, prediction_intervals)\n",
    "preds, intervals = model.predict(n_periods=12, alpha=0.05, \n",
    "                                 return_conf_int=True)\n",
    "```\n",
    "\n",
    " >Note: Both `pmdarima` and `statsmodels` call prediction intervals a confidence interval.  But that's technically incorrect!\n",
    " \n",
    "**Task:**\n",
    "* For each of the three models you have fitted make a 24 month forecast\n",
    "* Return the point forecast and a 95% prediction interval.\n",
    "* Plot each models forecast.\n",
    "\n",
    "**Hints**:\n",
    "* The `predict()` method returns a `numpy.ndarray`.  To help with plotting the forecast along with the training data it is useful to convert these into a `pandas.DataFrame` with a `DateTimeIndex`.  To do that, you can use the helper function `arima_preds_to_dataframe()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6: Rolling Forecast Origin - Cross Validation\n",
    "\n",
    "The module `pmdarima.model_selection` includes some built in cross validation tools for the ARIMA models.  Let's use these to compare the three models you have created over a 6 month horizon.\n",
    "\n",
    "To import a rolling forecast origin functionality run the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pmdarima.model_selection import RollingForecastCV, cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will score forecast error using the mean absolute error metric.  \n",
    "\n",
    "A template for cross validation is as follows:\n",
    "\n",
    "```python\n",
    "#6 month horizon that rolls the origin by 1 month at a time.\n",
    "#by default it uses 1/3 of the data for initial training.\n",
    "cv = RollingForecastCV(h=6, step=1)\n",
    "\n",
    "#perform cv. (verbose controls the output to screen).\n",
    "scores = cross_val_score(model_1, y_train, cv=cv, verbose=2, \n",
    "                              scoring='mean_absolute_error')\n",
    "\n",
    "```\n",
    "\n",
    "**Task:**\n",
    "* Using 6 month horizon calculate the mean cross validation score for each model.\n",
    "\n",
    "**Questions:**\n",
    "* Which model do you prefer for point forecasts and why?  Was it a difficult decision?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 7: Is the ARIMA model better than a Naive Forecast?\n",
    "\n",
    "Let's calculate a cross validation score for the seasonal naive model and compare it to your chosen ARIMA model.  \n",
    "\n",
    "**Task**:\n",
    "\n",
    "* Using code provided below evaluate if your chosen ARIMA model relative to a Seaonal Naive forecast.\n",
    "\n",
    "**Questions**:\n",
    "* Are you happy with your chosen ARIMA model? Would select it over a seasonal naive model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
